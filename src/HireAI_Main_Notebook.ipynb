{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional, TypedDict\n",
    "from dataclasses import dataclass\n",
    "import re"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Deep Learning & NLP\n",
    "from transformers import (\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    prepare_model_for_kbit_training,\n",
    ")\n",
    "from datasets import Dataset"
   ],
   "id": "bbd06a95529d59e4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# LangChain & LangGraph\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# Utilities\n",
    "from sentence_transformers import CrossEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "id": "4fff1144beedd118",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\" All libraries imported successfully!\")\n",
    "print(f\" PyTorch version: {torch.__version__}\")\n",
    "print(f\" CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"üíª GPU: {torch.cuda.get_device_name(0)}\")"
   ],
   "id": "e599f7c6c2a792d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class ProjectConfig:\n",
    "    BASE_DIR: Path = Path(\"../../JupyterProject\")\n",
    "    DATA_DIR: Path = BASE_DIR / \"data\"\n",
    "    MODEL_DIR: Path = BASE_DIR / \"models\"\n",
    "    RESULTS_DIR: Path = BASE_DIR / \"results\"\n",
    "    VECTOR_DB_DIR: Path = BASE_DIR / \"vector_db\"\n",
    "    BASE_MODEL: str = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "    EMBEDDING_MODEL: str = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    RERANKER_MODEL: str = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n",
    "    CHUNK_SIZE: int = 500\n",
    "    CHUNK_OVERLAP: int = 50\n",
    "    TOP_K_RETRIEVAL: int = 5\n",
    "    RERANK_TOP_K: int = 3\n",
    "    # Fine-tuning settings\n",
    "    LORA_R: int = 16\n",
    "    LORA_ALPHA: int = 32\n",
    "    LORA_DROPOUT: float = 0.05\n",
    "    LEARNING_RATE: float = 2e-4\n",
    "    BATCH_SIZE: int = 4\n",
    "    GRADIENT_ACCUMULATION_STEPS: int = 4\n",
    "    NUM_EPOCHS: int = 3\n",
    "    MAX_SEQ_LENGTH: int = 2048\n",
    "\n",
    "    # Agent settings\n",
    "    MAX_ITERATIONS: int = 5\n",
    "    TEMPERATURE: float = 0.7\n",
    "\n",
    "    def __post_init__(self):\n",
    "        \"\"\"Create necessary directories\"\"\"\n",
    "        for directory in [self.DATA_DIR, self.MODEL_DIR,\n",
    "                self.VECTOR_DB_DIR, self.RESULTS_DIR]:\n",
    "            directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "config = ProjectConfig()\n",
    "print(f\"üìÅ Project initialized at: {config.BASE_DIR}\")"
   ],
   "id": "8071f403e8902c76",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class ResumeParser:\n",
    "    \"\"\"Parse and extract structured information from resumes\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.skills_keywords = [\n",
    "            'python', 'java', 'javascript', 'react', 'sql', 'machine learning',\n",
    "            'deep learning', 'nlp', 'computer vision', 'aws', 'docker', 'kubernetes'\n",
    "        ]\n",
    "\n",
    "    def parse_pdf(self, pdf_path: str) -> Dict[str, Any]:\n",
    "        \"\"\"Extract text and metadata from PDF resume\"\"\"\n",
    "        from pypdf import PdfReader\n",
    "\n",
    "        reader = PdfReader(pdf_path)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "\n",
    "        return {\n",
    "            'text': text,\n",
    "            'num_pages': len(reader.pages),\n",
    "            'metadata': self._extract_metadata(text)\n",
    "        }\n",
    "\n",
    "    def _extract_metadata(self, text: str) -> Dict[str, Any]:\n",
    "        \"\"\"Extract structured data from resume text\"\"\"\n",
    "        metadata = {\n",
    "            'email': self._extract_email(text),\n",
    "            'phone': self._extract_phone(text),\n",
    "            'skills': self._extract_skills(text),\n",
    "            'education': self._extract_education(text),\n",
    "            'experience_years': self._estimate_experience(text)\n",
    "        }\n",
    "        return metadata\n",
    "\n",
    "    def _extract_email(self, text: str) -> Optional[str]:\n",
    "        \"\"\"Extract email address\"\"\"\n",
    "        email_pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
    "        matches = re.findall(email_pattern, text)\n",
    "        return matches[0] if matches else None\n",
    "\n",
    "    def _extract_phone(self, text: str) -> Optional[str]:\n",
    "        \"\"\"Extract phone number\"\"\"\n",
    "        phone_pattern = r'(\\+?\\d{1,3}[-.\\s]?)?\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}'\n",
    "        matches = re.findall(phone_pattern, text)\n",
    "        return matches[0] if matches else None\n",
    "\n",
    "    def _extract_skills(self, text: str) -> List[str]:\n",
    "        \"\"\"Extract technical skills\"\"\"\n",
    "        text_lower = text.lower()\n",
    "        found_skills = [skill for skill in self.skills_keywords\n",
    "                       if skill in text_lower]\n",
    "        return found_skills\n",
    "\n",
    "    def _extract_education(self, text: str) -> List[str]:\n",
    "        \"\"\"Extract education degrees\"\"\"\n",
    "        degrees = ['phd', 'ph.d', 'master', 'bachelor', 'mba', 'ms', 'bs', 'ba']\n",
    "        text_lower = text.lower()\n",
    "        found_degrees = [deg for deg in degrees if deg in text_lower]\n",
    "        return list(set(found_degrees))\n",
    "\n",
    "    def _estimate_experience(self, text: str) -> int:\n",
    "        \"\"\"Estimate years of experience\"\"\"\n",
    "        # Look for patterns like \"5 years\", \"2+ years\", etc.\n",
    "        pattern = r'(\\d+)\\+?\\s*years?'\n",
    "        matches = re.findall(pattern, text.lower())\n",
    "        if matches:\n",
    "            return max([int(m) for m in matches])\n",
    "        return 0"
   ],
   "id": "ef8bfde934a6a70",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def generate_synthetic_resumes(n_samples: int = 100) -> pd.DataFrame:\n",
    "    \"\"\"Generate synthetic resume data for training\"\"\"\n",
    "\n",
    "    job_titles = ['Software Engineer', 'Data Scientist', 'Product Manager',\n",
    "                  'DevOps Engineer', 'ML Engineer', 'Frontend Developer']\n",
    "\n",
    "    skills_pool = {\n",
    "        'Software Engineer': ['Python', 'Java', 'JavaScript', 'React', 'Node.js', 'SQL', 'Git'],\n",
    "        'Data Scientist': ['Python', 'R', 'SQL', 'Machine Learning', 'Pandas', 'Scikit-learn', 'TensorFlow'],\n",
    "        'Product Manager': ['Agile', 'Jira', 'User Research', 'Roadmapping', 'SQL', 'Analytics'],\n",
    "        'DevOps Engineer': ['Docker', 'Kubernetes', 'AWS', 'CI/CD', 'Terraform', 'Linux', 'Python'],\n",
    "        'ML Engineer': ['Python', 'TensorFlow', 'PyTorch', 'MLOps', 'Docker', 'AWS', 'Kubernetes'],\n",
    "        'Frontend Developer': ['JavaScript', 'React', 'Vue.js', 'HTML', 'CSS', 'TypeScript', 'Webpack']\n",
    "    }\n",
    "\n",
    "    data = []\n",
    "    for i in range(n_samples):\n",
    "        job_title = np.random.choice(job_titles)\n",
    "        experience_years = np.random.randint(0, 15)\n",
    "        education = np.random.choice(['Bachelor', 'Master', 'PhD'])\n",
    "        skills = np.random.choice(skills_pool[job_title],\n",
    "                                 size=np.random.randint(3, 7),\n",
    "                                 replace=False).tolist()\n",
    "\n",
    "        # Generate resume text\n",
    "        resume_text = f\"\"\"\n",
    "        Professional Summary:\n",
    "        {job_title} with {experience_years} years of experience in software development.\n",
    "\n",
    "        Education:\n",
    "        {education}'s Degree in Computer Science\n",
    "\n",
    "        Skills:\n",
    "        {', '.join(skills)}\n",
    "\n",
    "        Experience:\n",
    "        - Led development teams and delivered multiple projects\n",
    "        - Implemented best practices and coding standards\n",
    "        - Collaborated with cross-functional teams\n",
    "        \"\"\"\n",
    "\n",
    "        data.append({\n",
    "            'resume_id': f'RES_{i:04d}',\n",
    "            'job_title': job_title,\n",
    "            'experience_years': experience_years,\n",
    "            'education': education,\n",
    "            'skills': skills,\n",
    "            'resume_text': resume_text.strip()\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def generate_job_descriptions(n_samples: int = 50) -> pd.DataFrame:\n",
    "    \"\"\"Generate synthetic job descriptions\"\"\"\n",
    "\n",
    "    job_titles = ['Software Engineer', 'Data Scientist', 'Product Manager',\n",
    "                  'DevOps Engineer', 'ML Engineer', 'Frontend Developer']\n",
    "\n",
    "    data = []\n",
    "    for i in range(n_samples):\n",
    "        job_title = np.random.choice(job_titles)\n",
    "        required_exp = np.random.randint(2, 10)\n",
    "\n",
    "        jd_text = f\"\"\"\n",
    "        Position: {job_title}\n",
    "\n",
    "        Requirements:\n",
    "        - {required_exp}+ years of experience in relevant field\n",
    "        - Bachelor's degree in Computer Science or related field\n",
    "        - Strong problem-solving and communication skills\n",
    "\n",
    "        Responsibilities:\n",
    "        - Design and implement scalable solutions\n",
    "        - Collaborate with team members\n",
    "        - Mentor junior developers\n",
    "        \"\"\"\n",
    "\n",
    "        data.append({\n",
    "            'job_id': f'JOB_{i:04d}',\n",
    "            'job_title': job_title,\n",
    "            'required_experience': required_exp,\n",
    "            'job_description': jd_text.strip()\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Generate datasets\n",
    "print(\" Generating synthetic datasets...\")\n",
    "resumes_df = generate_synthetic_resumes(100)\n",
    "jobs_df = generate_job_descriptions(50)\n",
    "\n",
    "print(f\" Generated {len(resumes_df)} resumes and {len(jobs_df)} job descriptions\")\n",
    "print(\"\\n Sample Resume:\")\n",
    "print(resumes_df.iloc[0]['resume_text'][:300] + \"...\")\n",
    "print(f\"\\n Sample Job Description:\")\n",
    "print(jobs_df.iloc[0]['job_description'][:300] + \"...\")\n",
    "\n",
    "# Save datasets\n",
    "resumes_df.to_csv(config.DATA_DIR / 'resumes.csv', index=False)\n",
    "jobs_df.to_csv(config.DATA_DIR / 'job_descriptions.csv', index=False)"
   ],
   "id": "1a44db95c19183d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class DocumentProcessor:\n",
    "    \"\"\"Process and chunk documents for RAG\"\"\"\n",
    "\n",
    "    def __init__(self, chunk_size: int = 500, chunk_overlap: int = 50):\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=chunk_overlap,\n",
    "            separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "            length_function=len\n",
    "        )\n",
    "\n",
    "    def process_resumes(self, resumes_df: pd.DataFrame) -> List[Document]:\n",
    "        \"\"\"Convert resumes to Document objects with metadata\"\"\"\n",
    "        documents = []\n",
    "\n",
    "        for idx, row in resumes_df.iterrows():\n",
    "            doc = Document(\n",
    "                page_content=row['resume_text'],\n",
    "                metadata={\n",
    "                    'type': 'resume',\n",
    "                    'resume_id': row['resume_id'],\n",
    "                    'job_title': row['job_title'],\n",
    "                    'experience_years': row['experience_years'],\n",
    "                    'education': row['education'],\n",
    "                    'skills': ','.join(row['skills'])\n",
    "                }\n",
    "            )\n",
    "            documents.append(doc)\n",
    "\n",
    "        return documents\n",
    "\n",
    "    def process_job_descriptions(self, jobs_df: pd.DataFrame) -> List[Document]:\n",
    "        \"\"\"Convert job descriptions to Document objects\"\"\"\n",
    "        documents = []\n",
    "\n",
    "        for idx, row in jobs_df.iterrows():\n",
    "            doc = Document(\n",
    "                page_content=row['job_description'],\n",
    "                metadata={\n",
    "                    'type': 'job_description',\n",
    "                    'job_id': row['job_id'],\n",
    "                    'job_title': row['job_title'],\n",
    "                    'required_experience': row['required_experience']\n",
    "                }\n",
    "            )\n",
    "            documents.append(doc)\n",
    "\n",
    "        return documents\n",
    "\n",
    "    def chunk_documents(self, documents: List[Document]) -> List[Document]:\n",
    "        \"\"\"Split documents into chunks\"\"\"\n",
    "        return self.text_splitter.split_documents(documents)\n",
    "\n",
    "# Process documents\n",
    "print(\" Processing documents for RAG...\")\n",
    "processor = DocumentProcessor(\n",
    "    chunk_size=config.CHUNK_SIZE,\n",
    "    chunk_overlap=config.CHUNK_OVERLAP\n",
    ")\n",
    "\n",
    "resume_docs = processor.process_resumes(resumes_df)\n",
    "job_docs = processor.process_job_descriptions(jobs_df)\n",
    "all_docs = resume_docs + job_docs\n",
    "\n",
    "# Chunk documents\n",
    "chunked_docs = processor.chunk_documents(all_docs)\n",
    "print(f\"Created {len(chunked_docs)} document chunks from {len(all_docs)} documents\")\n",
    "print(f\"Average chunk size: {np.mean([len(doc.page_content) for doc in chunked_docs]):.0f} characters\")\n"
   ],
   "id": "f22d2caf5b7b65e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class HybridRetriever:\n",
    "    \"\"\"Hybrid retrieval system combining dense and sparse retrieval\"\"\"\n",
    "\n",
    "    def __init__(self, documents: List[Document], config: ProjectConfig):\n",
    "        self.config = config\n",
    "        self.documents = documents\n",
    "\n",
    "        # Dense retrieval (semantic)\n",
    "        print(\"Initializing dense retriever (embeddings)...\")\n",
    "        self.embeddings = HuggingFaceEmbeddings(\n",
    "            model_name= config.EMBEDDING_MODEL,\n",
    "            model_kwargs={'device': 'cuda' if torch.cuda.is_available() else 'cpu'}\n",
    "        )\n",
    "\n",
    "        self.vectorstore = Chroma.from_documents(\n",
    "            documents=documents,\n",
    "            embedding=self.embeddings,\n",
    "            persist_directory=str(config.VECTOR_DB_DIR)\n",
    "        )\n",
    "\n",
    "        # Sparse retrieval (BM25)\n",
    "        print(\"Initializing sparse retriever (BM25)...\")\n",
    "        from rank_bm25 import BM25Okapi\n",
    "        tokenized_docs = [doc.page_content.lower().split() for doc in documents]\n",
    "        self.bm25 = BM25Okapi(tokenized_docs)\n",
    "\n",
    "        # Re-ranker\n",
    "        print(\"Loading re-ranker model...\")\n",
    "        self.reranker = CrossEncoder(config.RERANKER_MODEL)\n",
    "\n",
    "        print(\"Hybrid retriever initialized!\")\n",
    "\n",
    "    def retrieve(self, query: str, k: int = 5) -> List[Document]:\n",
    "        \"\"\"Hybrid retrieval with re-ranking\"\"\"\n",
    "\n",
    "        # Dense retrieval\n",
    "        dense_results = self.vectorstore.similarity_search(query, k=k*2)\n",
    "\n",
    "        # Sparse retrieval\n",
    "        tokenized_query = query.lower().split()\n",
    "        bm25_scores = self.bm25.get_scores(tokenized_query)\n",
    "        top_bm25_indices = np.argsort(bm25_scores)[-k*2:][::-1]\n",
    "        sparse_results = [self.documents[i] for i in top_bm25_indices]\n",
    "\n",
    "        # Combine and deduplicate\n",
    "        combined_results = list({doc.page_content: doc\n",
    "                                for doc in dense_results + sparse_results}.values())\n",
    "\n",
    "        # Re-rank\n",
    "        if len(combined_results) > k:\n",
    "            pairs = [[query, doc.page_content] for doc in combined_results]\n",
    "            scores = self.reranker.predict(pairs)\n",
    "            top_indices = np.argsort(scores)[-k:][::-1]\n",
    "            combined_results = [combined_results[i] for i in top_indices]\n",
    "\n",
    "        return combined_results[:k]\n",
    "\n",
    "# Initialize retriever\n",
    "print(\"\\nBuilding Hybrid RAG System...\")\n",
    "retriever = HybridRetriever(chunked_docs, config)\n",
    "\n",
    "# Test retrieval\n",
    "test_query = \"Senior software engineer with Python and machine learning experience\"\n",
    "retrieved_docs = retriever.retrieve(test_query, k=3)\n",
    "\n",
    "print(f\"\\nTest Query: '{test_query}'\")\n",
    "print(f\"Retrieved {len(retrieved_docs)} relevant documents:\")\n",
    "for i, doc in enumerate(retrieved_docs, 1):\n",
    "    print(f\"\\n{i}. Type: {doc.metadata.get('type', 'unknown')}\")\n",
    "    print(f\"   Content: {doc.page_content[:150]}...\")"
   ],
   "id": "167af36e2f5ba46b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## 4.1 Prepare Training Data\n",
    "\n",
    "def create_training_dataset(resumes_df: pd.DataFrame, jobs_df: pd.DataFrame) -> Dataset:\n",
    "    \"\"\"Create instruction-tuning dataset for hiring tasks\"\"\"\n",
    "\n",
    "    training_samples = []\n",
    "\n",
    "    # Task 1: Resume Analysis\n",
    "    for _, resume in resumes_df.iterrows():\n",
    "        job = jobs_df.sample(1).iloc[0]\n",
    "\n",
    "        instruction = \"Analyze the following resume against the job requirements and provide a match score with explanation.\"\n",
    "        input_text = f\"Resume:\\n{resume['resume_text']}\\n\\nJob Description:\\n{job['job_description']}\"\n",
    "\n",
    "        # Generate synthetic output\n",
    "        skill_match = len(set(resume['skills'])) / 7.0  # Normalize\n",
    "        exp_match = min(resume['experience_years'] / job['required_experience'], 1.0)\n",
    "        overall_score = int((skill_match * 0.6 + exp_match * 0.4) * 100)\n",
    "\n",
    "        output = f\"\"\"Match Score: {overall_score}/100\n",
    "\n",
    "Strengths:\n",
    "- {resume['experience_years']} years of relevant experience\n",
    "- Skills: {', '.join(resume['skills'][:3])}\n",
    "- Education: {resume['education']}'s degree\n",
    "\n",
    "Recommendation: {\"STRONG MATCH\" if overall_score > 70 else \"MODERATE MATCH\" if overall_score > 50 else \"WEAK MATCH\"}\"\"\"\n",
    "\n",
    "        training_samples.append({\n",
    "            'instruction': instruction,\n",
    "            'input': input_text,\n",
    "            'output': output\n",
    "        })\n",
    "\n",
    "    # Task 2: Interview Question Generation\n",
    "    for _, job in jobs_df[:20].iterrows():\n",
    "        instruction = \"Generate 5 technical interview questions for this role.\"\n",
    "        input_text = f\"Job Title: {job['job_title']}\\n\\n{job['job_description']}\"\n",
    "\n",
    "        output = f\"\"\"Interview Questions for {job['job_title']}:\n",
    "\n",
    "1. Technical: Describe your experience with the core technologies required for this role.\n",
    "2. Problem-Solving: Walk me through how you would approach [specific technical challenge].\n",
    "3. Experience: Tell me about a complex project you've delivered. What was your role?\n",
    "4. Collaboration: How do you handle disagreements with team members on technical decisions?\n",
    "5. Growth: What areas are you currently working to improve in your skillset?\"\"\"\n",
    "\n",
    "        training_samples.append({\n",
    "            'instruction': instruction,\n",
    "            'input': input_text,\n",
    "            'output': output\n",
    "        })\n",
    "\n",
    "    # Task 3: Skills Gap Analysis\n",
    "    for _, resume in resumes_df[:20].iterrows():\n",
    "        job = jobs_df.sample(1).iloc[0]\n",
    "\n",
    "        instruction = \"Identify skills gaps between the candidate and role requirements.\"\n",
    "        input_text = f\"Candidate Skills: {', '.join(resume['skills'])}\\n\\nRequired for: {job['job_title']}\"\n",
    "\n",
    "        output = f\"\"\"Skills Gap Analysis:\n",
    "\n",
    "Current Skills: {', '.join(resume['skills'][:4])}\n",
    "Missing Critical Skills: [Based on role requirements]\n",
    "Nice-to-Have Skills: [Additional beneficial skills]\n",
    "\n",
    "Recommendation: Focus on developing [specific skills] through online courses or projects.\"\"\"\n",
    "\n",
    "        training_samples.append({\n",
    "            'instruction': instruction,\n",
    "            'input': input_text,\n",
    "            'output': output\n",
    "        })\n",
    "\n",
    "    return Dataset.from_list(training_samples)\n",
    "\n",
    "# Create training dataset\n",
    "print(\"Creating instruction-tuning dataset...\")\n",
    "train_dataset = create_training_dataset(resumes_df, jobs_df)\n",
    "print(f\"Created {len(train_dataset)} training examples\")\n",
    "print(f\"\\n Sample training example:\")\n",
    "print(f\"Instruction: {train_dataset[0]['instruction']}\")\n",
    "print(f\"Input: {train_dataset[0]['input'][:150]}...\")\n",
    "print(f\"Output: {train_dataset[0]['output'][:150]}...\")"
   ],
   "id": "5d6a951247e99fff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def format_prompt(sample: Dict[str, str]) -> str:\n",
    "    \"\"\"Format sample into instruction-following prompt\"\"\"\n",
    "    return f\"\"\"<s>[INST] {sample['instruction']}\n",
    "\n",
    "{sample['input']} [/INST] {sample['output']}</s>\"\"\"\n",
    "\n",
    "def tokenize_function(examples, tokenizer, max_length: int = 2048):\n",
    "    \"\"\"Tokenize examples for training\"\"\"\n",
    "    prompts = [format_prompt({\"instruction\": inst, \"input\": inp, \"output\": out})\n",
    "               for inst, inp, out in zip(examples[\"instruction\"],\n",
    "                                         examples[\"input\"],\n",
    "                                         examples[\"output\"])]\n",
    "\n",
    "    tokenized = tokenizer(\n",
    "        prompts,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"].clone()\n",
    "    return tokenized"
   ],
   "id": "7d0ec0771881b234",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## 4.4 Configure LoRA for fine tuning\n",
    "\n",
    "def setup_lora(model, config: ProjectConfig):\n",
    "    \"\"\"Configure and apply LoRA to the model\"\"\"\n",
    "\n",
    "    print(\"Configuring LoRA...\")\n",
    "\n",
    "    # LoRA configuration\n",
    "    lora_config = LoraConfig(\n",
    "        r=config.LORA_R,\n",
    "        lora_alpha=config.LORA_ALPHA,\n",
    "        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                       \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "        lora_dropout=config.LORA_DROPOUT,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\"\n",
    "    )\n",
    "\n",
    "    # Prepare model for training\n",
    "    model = prepare_model_for_kbit_training(model)\n",
    "    model = get_peft_model(model, lora_config)\n",
    "\n",
    "    # Print trainable parameters\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "    print(f\" LoRA configured successfully!\")\n",
    "    print(f\"Trainable parameters: {trainable_params:,} ({trainable_params/total_params*100:.2f}%)\")\n",
    "\n",
    "    return model"
   ],
   "id": "dea771b39c90e83f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def train_model(model, tokenizer, train_dataset, config: ProjectConfig):\n",
    "    \"\"\"Fine-tune model with LoRA\"\"\"\n",
    "\n",
    "    print(\"Starting model training...\")\n",
    "\n",
    "    # Tokenize dataset\n",
    "    tokenized_dataset = train_dataset.map(\n",
    "        lambda x: tokenize_function(x, tokenizer, config.MAX_SEQ_LENGTH),\n",
    "        batched=True,\n",
    "        remove_columns=train_dataset.column_names\n",
    "    )\n",
    "\n",
    "    # Training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=str(config.MODEL_DIR / \"checkpoints\"),\n",
    "        num_train_epochs=config.NUM_EPOCHS,\n",
    "        per_device_train_batch_size=config.BATCH_SIZE,\n",
    "        gradient_accumulation_steps=config.GRADIENT_ACCUMULATION_STEPS,\n",
    "        learning_rate=config.LEARNING_RATE,\n",
    "        fp16=True,\n",
    "        logging_steps=10,\n",
    "        save_strategy=\"epoch\",\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        warmup_steps=50,\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "        report_to=\"none\"\n",
    "    )\n",
    "\n",
    "    # Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_dataset,\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    # Train\n",
    "    trainer.train()\n",
    "\n",
    "    print(\"Training completed!\")\n",
    "\n",
    "    # Save model\n",
    "    model.save_pretrained(config.MODEL_DIR / \"final_model\")\n",
    "    tokenizer.save_pretrained(config.MODEL_DIR / \"final_model\")\n",
    "\n",
    "    return model, tokenizer"
   ],
   "id": "d982423deb208566",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "def load_base_model(config: ProjectConfig):\n",
    "\n",
    "    print(f\"Loading CPU model: {config.BASE_MODEL}\")\n",
    "    print(\"Using 16-bit (no quantization - CPU safe)\")\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        config.BASE_MODEL,\n",
    "        dtype=torch.float16,\n",
    "        device_map={\"\": \"cpu\"},\n",
    "        low_cpu_mem_usage=True,\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "\n",
    "    # Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        config.BASE_MODEL,\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.padding_side = \"right\"\n",
    "\n",
    "    print(\" CPU model loaded successfully!\")\n",
    "    print(f\" Model size: {model.get_memory_footprint() / 1e9:.2f} GB\")\n",
    "    print(f\"üñ•  Running on: CPU (16-bit, 8GB RAM)\")\n",
    "\n",
    "    return model, tokenizer"
   ],
   "id": "731587a1248602db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# NOTE: Due to computational constraints in this notebook, we'll simulate training My pc is dying HAHA!\n",
    "'''\n",
    "\n",
    "# Load and prepare model\n",
    "base_model, tokenizer = load_base_model(config)\n",
    "lora_model = setup_lora(base_model, config)\n",
    "\n",
    "# Fine-tune\n",
    "fine_tuned_model, tokenizer = train_model(lora_model, tokenizer, train_dataset, config)\n",
    "'''\n",
    "'''\n",
    "this is where my pc is shutting down and won't complete this is for testing\n",
    "import os\n",
    "from transformers import AutoModelForCausalLM\n",
    "import time\n",
    "\n",
    "def safe_download_model(model_name, max_retries=3):\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            print(f\"Attempt {attempt + 1}/{max_retries}\")\n",
    "            model = AutoModelForCausalLM.from_pretrained(\n",
    "                model_name,\n",
    "                timeout=600,\n",
    "                resume_download=True,\n",
    "                cache_dir=\"./hf_cache\",\n",
    "                low_cpu_mem_usage=True\n",
    "            )\n",
    "            print(\"‚úÖ Download successful!\")\n",
    "            return model\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Attempt {attempt + 1} failed: {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(10)\n",
    "\n",
    "    raise Exception(\"All download attempts failed\")\n",
    "'''\n",
    "# and this is for real life training maybe it will need some changes\n",
    "#model = safe_download_model(config.BASE_MODEL)\n",
    "# model = AutoModelForCausalLM.from_pretrained(config.BASE_MODEL)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(config.BASE_MODEL)"
   ],
   "id": "97b35aa8fc372c8f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class AgentState(TypedDict):\n",
    "    \"\"\"State object passed between agents\"\"\"\n",
    "    messages: List[str]\n",
    "    resume_text: Optional[str]\n",
    "    job_description: Optional[str]\n",
    "    retrieved_contexts: List[Dict]\n",
    "    resume_analysis: Optional[Dict]\n",
    "    interview_questions: Optional[List[str]]\n",
    "    skills_gaps: Optional[Dict]\n",
    "    current_agent: str\n",
    "    iteration: int"
   ],
   "id": "159502daede2563a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class ResumeAnalyzerAgent:\n",
    "    \"\"\"Analyzes resumes against job requirements\"\"\"\n",
    "\n",
    "    def __init__(self, retriever: HybridRetriever, model=None):\n",
    "        self.retriever = retriever\n",
    "        self.model = model\n",
    "\n",
    "    def analyze(self, state: AgentState) -> AgentState:\n",
    "        \"\"\"Analyze resume against job description\"\"\"\n",
    "\n",
    "        print(\"Resume Analyzer Agent activated...\")\n",
    "\n",
    "        resume_text = state.get(\"resume_text\", \"\")\n",
    "        job_desc = state.get(\"job_description\", \"\")\n",
    "\n",
    "        if not resume_text or not job_desc:\n",
    "            state[\"resume_analysis\"] = {\"error\": \"Missing resume or job description\"}\n",
    "            return state\n",
    "\n",
    "        # Retrieve relevant context\n",
    "        query = f\"Resume requirements for: {job_desc[:200]}\"\n",
    "        contexts = self.retriever.retrieve(query, k=config.TOP_K_RETRIEVAL)\n",
    "        state[\"retrieved_contexts\"] = [\n",
    "            {\"content\": doc.page_content, \"metadata\": doc.metadata}\n",
    "            for doc in contexts\n",
    "        ]\n",
    "\n",
    "        # Parse resume\n",
    "        parser = ResumeParser()\n",
    "        resume_metadata = parser._extract_metadata(resume_text)# update this needs to be removed\n",
    "\n",
    "        # Simple rule-based scoring (in production, use fine-tuned model)\n",
    "        skills_found = resume_metadata.get('skills', [])\n",
    "        experience = resume_metadata.get('experience_years', 0)\n",
    "\n",
    "        score = min(100, len(skills_found) * 15 + experience * 5)\n",
    "\n",
    "        analysis = {\n",
    "            \"overall_score\": score,\n",
    "            \"skills_found\": skills_found,\n",
    "            \"experience_years\": experience,\n",
    "            \"education\": resume_metadata.get('education', []),\n",
    "            \"recommendation\": \"Strong Match\" if score > 70 else \"Moderate Match\" if score > 50 else \"Weak Match\",\n",
    "            \"strengths\": [\n",
    "                f\"{experience} years of experience\",\n",
    "                f\"Skills: {', '.join(skills_found[:3])}\" if skills_found else \"N/A\"\n",
    "            ],\n",
    "            \"areas_for_review\": [\n",
    "                \"Verify specific project experience\",\n",
    "                \"Check cultural fit during interview\"\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        state[\"resume_analysis\"] = analysis\n",
    "        state[\"messages\"].append(f\"Resume Analysis Complete: {score}/100\")\n",
    "\n",
    "        print(f\"Analysis complete. Score: {score}/100\")\n",
    "\n",
    "        return state"
   ],
   "id": "7bb009611c752fe4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import random\n",
    "from typing import Dict, List, Any\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class QuestionTemplate:\n",
    "    \"\"\"Template for generating diverse questions\"\"\"\n",
    "    templates: List[str]\n",
    "    category: str\n",
    "    difficulty: str\n",
    "class InterviewQuestionBank:\n",
    "\n",
    "\n",
    "    # Technical Question Templates - Multiple variations\n",
    "    TECHNICAL_TEMPLATES = {\n",
    "        'experience': [\n",
    "            \"Can you walk me through a challenging project where you used {skill}?\",\n",
    "            \"Tell me about your most impactful work with {skill}. What was the outcome?\",\n",
    "            \"Describe a situation where {skill} was critical to solving a business problem.\",\n",
    "            \"What's the most complex implementation you've done using {skill}?\",\n",
    "            \"How have you applied {skill} to improve system performance or user experience?\",\n",
    "        ],\n",
    "        'problem_solving': [\n",
    "            \"How would you architect a solution using {skill} for [specific scenario]?\",\n",
    "            \"If you had to optimize a {skill}-based system serving millions of users, what would you focus on?\",\n",
    "            \"Walk me through how you'd debug a performance issue in a {skill} application.\",\n",
    "            \"What trade-offs would you consider when choosing {skill} vs alternative technologies?\",\n",
    "            \"Describe your approach to testing and validating {skill} implementations.\",\n",
    "        ],\n",
    "        'depth': [\n",
    "            \"What are the key limitations or challenges of {skill}, and how do you work around them?\",\n",
    "            \"How does {skill} work under the hood? Explain the core concepts.\",\n",
    "            \"What's a recent update or feature in {skill} that you find interesting? Why?\",\n",
    "            \"Compare {skill} with similar technologies. When would you choose one over the other?\",\n",
    "            \"What best practices do you follow when working with {skill}?\",\n",
    "        ],\n",
    "        'practical': [\n",
    "            \"Show me (or describe) how you would implement [specific feature] using {skill}.\",\n",
    "            \"What tools and workflows do you use alongside {skill} in your development process?\",\n",
    "            \"How do you stay current with {skill} developments and best practices?\",\n",
    "            \"Describe a mistake you made with {skill} and what you learned from it.\",\n",
    "            \"What metrics do you track when working with {skill} in production?\",\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Behavioral Question Templates by Theme\n",
    "    BEHAVIORAL_TEMPLATES = {\n",
    "        'collaboration': [\n",
    "            \"Tell me about a time when you had to collaborate with a difficult team member. How did you handle it?\",\n",
    "            \"Describe a situation where you had to explain a complex technical concept to non-technical stakeholders.\",\n",
    "            \"Give an example of when you received critical feedback. How did you respond?\",\n",
    "            \"Tell me about a time when your team disagreed on a technical approach. What was your role?\",\n",
    "            \"Describe how you've mentored or helped junior developers grow.\",\n",
    "        ],\n",
    "        'problem_solving': [\n",
    "            \"Walk me through the most challenging technical problem you've solved. What was your approach?\",\n",
    "            \"Tell me about a time when you had to make a critical decision with incomplete information.\",\n",
    "            \"Describe a situation where you had to fix a critical production bug under pressure.\",\n",
    "            \"Give an example of when you identified and solved a problem proactively before it became critical.\",\n",
    "            \"Tell me about a time when your initial solution didn't work. How did you adapt?\",\n",
    "        ],\n",
    "        'leadership': [\n",
    "            \"Describe a time when you had to lead a project or initiative. What was the outcome?\",\n",
    "            \"Tell me about a situation where you had to influence others without having formal authority.\",\n",
    "            \"Give an example of when you took ownership of a failing project and turned it around.\",\n",
    "            \"Describe how you've handled competing priorities from multiple stakeholders.\",\n",
    "            \"Tell me about a time when you had to make an unpopular decision. How did you handle it?\",\n",
    "        ],\n",
    "        'adaptability': [\n",
    "            \"Tell me about a time when project requirements changed significantly mid-development.\",\n",
    "            \"Describe a situation where you had to quickly learn a new technology or domain.\",\n",
    "            \"Give an example of when you had to work with legacy code or a system you didn't build.\",\n",
    "            \"Tell me about a time when you failed. What did you learn?\",\n",
    "            \"Describe how you've adapted to a major organizational or team change.\",\n",
    "        ],\n",
    "        'time_management': [\n",
    "            \"Tell me about a time when you had to manage multiple high-priority tasks. How did you prioritize?\",\n",
    "            \"Describe a situation where you had to deliver a project with a very tight deadline.\",\n",
    "            \"Give an example of when you had to say 'no' to a request to protect project quality.\",\n",
    "            \"Tell me about how you balance technical debt with feature development.\",\n",
    "            \"Describe your approach to estimating and managing complex projects.\",\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Situational Questions by Scenario Type\n",
    "    SITUATIONAL_TEMPLATES = {\n",
    "        'system_design': [\n",
    "            \"How would you design a system to handle {specific_requirement}?\",\n",
    "            \"If you had to scale {system_type} to 10x current load, what would be your approach?\",\n",
    "            \"Walk me through how you'd architect a solution for {use_case}.\",\n",
    "            \"What factors would you consider when designing {specific_feature}?\",\n",
    "            \"How would you ensure reliability and fault tolerance in {system_context}?\",\n",
    "        ],\n",
    "        'incident_response': [\n",
    "            \"If you discovered a security vulnerability in production, what would be your immediate steps?\",\n",
    "            \"How would you handle a situation where multiple critical systems are failing simultaneously?\",\n",
    "            \"What would you do if a deploy caused a 50% increase in error rates?\",\n",
    "            \"If a key team member leaves during a critical project phase, how would you handle it?\",\n",
    "            \"How would you respond to a customer reporting data corruption in production?\",\n",
    "        ],\n",
    "        'trade_offs': [\n",
    "            \"How do you balance code quality with delivery speed when under tight deadlines?\",\n",
    "            \"When would you choose to refactor existing code vs building new functionality?\",\n",
    "            \"How do you decide between building, buying, or using open-source solutions?\",\n",
    "            \"What's your approach to managing technical debt while delivering features?\",\n",
    "            \"How do you balance perfection with pragmatism in your work?\",\n",
    "        ],\n",
    "        'team_dynamics': [\n",
    "            \"How would you handle a situation where a team member consistently misses deadlines?\",\n",
    "            \"What would you do if you strongly disagreed with your manager's technical decision?\",\n",
    "            \"How would you approach code reviews to be constructive without demotivating teammates?\",\n",
    "            \"If two team members have conflicting ideas about architecture, how would you facilitate resolution?\",\n",
    "            \"How would you onboard a new developer to your codebase and team practices?\",\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Role-specific specialized questions\n",
    "    ROLE_SPECIFIC = {\n",
    "        'Software Engineer': [\n",
    "            \"How do you approach writing testable, maintainable code?\",\n",
    "            \"Describe your ideal code review process.\",\n",
    "            \"What's your experience with microservices vs monolithic architectures?\",\n",
    "            \"How do you ensure backward compatibility when updating APIs?\",\n",
    "        ],\n",
    "        'Data Scientist': [\n",
    "            \"How do you validate that a machine learning model is ready for production?\",\n",
    "            \"Describe your approach to feature engineering for [specific problem].\",\n",
    "            \"How do you handle imbalanced datasets?\",\n",
    "            \"What's your process for explaining model predictions to stakeholders?\",\n",
    "        ],\n",
    "        'DevOps Engineer': [\n",
    "            \"How would you implement zero-downtime deployments?\",\n",
    "            \"Describe your approach to monitoring and alerting strategies.\",\n",
    "            \"How do you handle secrets management in CI/CD pipelines?\",\n",
    "            \"What's your strategy for infrastructure as code testing?\",\n",
    "        ],\n",
    "        'ML Engineer': [\n",
    "            \"How do you monitor and detect model drift in production?\",\n",
    "            \"Describe your approach to A/B testing ML models.\",\n",
    "            \"How do you optimize model inference latency?\",\n",
    "            \"What's your strategy for versioning and reproducing ML experiments?\",\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Enhanced Interview Assistant Agent with Dynamic Question Generation\n",
    "===================================================================\n",
    "Generates diverse, context-aware interview questions that adapt to:\n",
    "- Candidate's skill level\n",
    "- Specific technologies\n",
    "- Experience gaps\n",
    "- Role requirements\n",
    "\"\"\"\n",
    "\n",
    "import random\n",
    "from typing import Dict, List, Any\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class QuestionTemplate:\n",
    "    \"\"\"Template for generating diverse questions\"\"\"\n",
    "    templates: List[str]\n",
    "    category: str\n",
    "    difficulty: str\n",
    "\n",
    "\n",
    "class InterviewQuestionBank:\n",
    "    \"\"\"Rich bank of diverse question templates\"\"\"\n",
    "\n",
    "    # Technical Question Templates - Multiple variations\n",
    "    TECHNICAL_TEMPLATES = {\n",
    "        'experience': [\n",
    "            \"Can you walk me through a challenging project where you used {skill}?\",\n",
    "            \"Tell me about your most impactful work with {skill}. What was the outcome?\",\n",
    "            \"Describe a situation where {skill} was critical to solving a business problem.\",\n",
    "            \"What's the most complex implementation you've done using {skill}?\",\n",
    "            \"How have you applied {skill} to improve system performance or user experience?\",\n",
    "        ],\n",
    "        'problem_solving': [\n",
    "            \"How would you architect a solution using {skill} for [specific scenario]?\",\n",
    "            \"If you had to optimize a {skill}-based system serving millions of users, what would you focus on?\",\n",
    "            \"Walk me through how you'd debug a performance issue in a {skill} application.\",\n",
    "            \"What trade-offs would you consider when choosing {skill} vs alternative technologies?\",\n",
    "            \"Describe your approach to testing and validating {skill} implementations.\",\n",
    "        ],\n",
    "        'depth': [\n",
    "            \"What are the key limitations or challenges of {skill}, and how do you work around them?\",\n",
    "            \"How does {skill} work under the hood? Explain the core concepts.\",\n",
    "            \"What's a recent update or feature in {skill} that you find interesting? Why?\",\n",
    "            \"Compare {skill} with similar technologies. When would you choose one over the other?\",\n",
    "            \"What best practices do you follow when working with {skill}?\",\n",
    "        ],\n",
    "        'practical': [\n",
    "            \"Show me (or describe) how you would implement [specific feature] using {skill}.\",\n",
    "            \"What tools and workflows do you use alongside {skill} in your development process?\",\n",
    "            \"How do you stay current with {skill} developments and best practices?\",\n",
    "            \"Describe a mistake you made with {skill} and what you learned from it.\",\n",
    "            \"What metrics do you track when working with {skill} in production?\",\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Behavioral Question Templates by Theme\n",
    "    BEHAVIORAL_TEMPLATES = {\n",
    "        'collaboration': [\n",
    "            \"Tell me about a time when you had to collaborate with a difficult team member. How did you handle it?\",\n",
    "            \"Describe a situation where you had to explain a complex technical concept to non-technical stakeholders.\",\n",
    "            \"Give an example of when you received critical feedback. How did you respond?\",\n",
    "            \"Tell me about a time when your team disagreed on a technical approach. What was your role?\",\n",
    "            \"Describe how you've mentored or helped junior developers grow.\",\n",
    "        ],\n",
    "        'problem_solving': [\n",
    "            \"Walk me through the most challenging technical problem you've solved. What was your approach?\",\n",
    "            \"Tell me about a time when you had to make a critical decision with incomplete information.\",\n",
    "            \"Describe a situation where you had to fix a critical production bug under pressure.\",\n",
    "            \"Give an example of when you identified and solved a problem proactively before it became critical.\",\n",
    "            \"Tell me about a time when your initial solution didn't work. How did you adapt?\",\n",
    "        ],\n",
    "        'leadership': [\n",
    "            \"Describe a time when you had to lead a project or initiative. What was the outcome?\",\n",
    "            \"Tell me about a situation where you had to influence others without having formal authority.\",\n",
    "            \"Give an example of when you took ownership of a failing project and turned it around.\",\n",
    "            \"Describe how you've handled competing priorities from multiple stakeholders.\",\n",
    "            \"Tell me about a time when you had to make an unpopular decision. How did you handle it?\",\n",
    "        ],\n",
    "        'adaptability': [\n",
    "            \"Tell me about a time when project requirements changed significantly mid-development.\",\n",
    "            \"Describe a situation where you had to quickly learn a new technology or domain.\",\n",
    "            \"Give an example of when you had to work with legacy code or a system you didn't build.\",\n",
    "            \"Tell me about a time when you failed. What did you learn?\",\n",
    "            \"Describe how you've adapted to a major organizational or team change.\",\n",
    "        ],\n",
    "        'time_management': [\n",
    "            \"Tell me about a time when you had to manage multiple high-priority tasks. How did you prioritize?\",\n",
    "            \"Describe a situation where you had to deliver a project with a very tight deadline.\",\n",
    "            \"Give an example of when you had to say 'no' to a request to protect project quality.\",\n",
    "            \"Tell me about how you balance technical debt with feature development.\",\n",
    "            \"Describe your approach to estimating and managing complex projects.\",\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Situational Questions by Scenario Type\n",
    "    SITUATIONAL_TEMPLATES = {\n",
    "        'system_design': [\n",
    "            \"How would you design a system to handle {specific_requirement}?\",\n",
    "            \"If you had to scale {system_type} to 10x current load, what would be your approach?\",\n",
    "            \"Walk me through how you'd architect a solution for {use_case}.\",\n",
    "            \"What factors would you consider when designing {specific_feature}?\",\n",
    "            \"How would you ensure reliability and fault tolerance in {system_context}?\",\n",
    "        ],\n",
    "        'incident_response': [\n",
    "            \"If you discovered a security vulnerability in production, what would be your immediate steps?\",\n",
    "            \"How would you handle a situation where multiple critical systems are failing simultaneously?\",\n",
    "            \"What would you do if a deploy caused a 50% increase in error rates?\",\n",
    "            \"If a key team member leaves during a critical project phase, how would you handle it?\",\n",
    "            \"How would you respond to a customer reporting data corruption in production?\",\n",
    "        ],\n",
    "        'trade_offs': [\n",
    "            \"How do you balance code quality with delivery speed when under tight deadlines?\",\n",
    "            \"When would you choose to refactor existing code vs building new functionality?\",\n",
    "            \"How do you decide between building, buying, or using open-source solutions?\",\n",
    "            \"What's your approach to managing technical debt while delivering features?\",\n",
    "            \"How do you balance perfection with pragmatism in your work?\",\n",
    "        ],\n",
    "        'team_dynamics': [\n",
    "            \"How would you handle a situation where a team member consistently misses deadlines?\",\n",
    "            \"What would you do if you strongly disagreed with your manager's technical decision?\",\n",
    "            \"How would you approach code reviews to be constructive without demotivating teammates?\",\n",
    "            \"If two team members have conflicting ideas about architecture, how would you facilitate resolution?\",\n",
    "            \"How would you onboard a new developer to your codebase and team practices?\",\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Role-specific specialized questions\n",
    "    ROLE_SPECIFIC = {\n",
    "        'Software Engineer': [\n",
    "            \"How do you approach writing testable, maintainable code?\",\n",
    "            \"Describe your ideal code review process.\",\n",
    "            \"What's your experience with microservices vs monolithic architectures?\",\n",
    "            \"How do you ensure backward compatibility when updating APIs?\",\n",
    "        ],\n",
    "        'Data Scientist': [\n",
    "            \"How do you validate that a machine learning model is ready for production?\",\n",
    "            \"Describe your approach to feature engineering for [specific problem].\",\n",
    "            \"How do you handle imbalanced datasets?\",\n",
    "            \"What's your process for explaining model predictions to stakeholders?\",\n",
    "        ],\n",
    "        'DevOps Engineer': [\n",
    "            \"How would you implement zero-downtime deployments?\",\n",
    "            \"Describe your approach to monitoring and alerting strategies.\",\n",
    "            \"How do you handle secrets management in CI/CD pipelines?\",\n",
    "            \"What's your strategy for infrastructure as code testing?\",\n",
    "        ],\n",
    "        'ML Engineer': [\n",
    "            \"How do you monitor and detect model drift in production?\",\n",
    "            \"Describe your approach to A/B testing ML models.\",\n",
    "            \"How do you optimize model inference latency?\",\n",
    "            \"What's your strategy for versioning and reproducing ML experiments?\",\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "class InterviewAssistantAgent:\n",
    "    \"\"\"Enhanced agent that generates diverse, contextual interview questions\"\"\"\n",
    "\n",
    "    def __init__(self, retriever=None, model=None):\n",
    "        self.retriever = retriever\n",
    "        self.model = model\n",
    "        self.question_bank = InterviewQuestionBank()\n",
    "        self.used_templates = set()\n",
    "    def generate_questions(self, state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Generate tailored, diverse interview questions\"\"\"\n",
    "\n",
    "        print(\"üí¨ Interview Assistant Agent activated...\")\n",
    "\n",
    "        job_desc = state.get(\"job_description\", \"\")\n",
    "        resume_analysis = state.get(\"resume_analysis\", {})\n",
    "\n",
    "        if not job_desc:\n",
    "            state[\"interview_questions\"] = []\n",
    "            return state\n",
    "\n",
    "        # Extract context\n",
    "        skills_found = resume_analysis.get(\"skills_found\", [])\n",
    "        experience_years = resume_analysis.get(\"experience_years\", 0)\n",
    "        job_title = self._extract_job_title(job_desc)\n",
    "\n",
    "        # Generate diverse questions\n",
    "        questions = {\n",
    "            \"technical\": self._generate_technical_questions(\n",
    "                skills_found,\n",
    "                experience_years,\n",
    "                job_title\n",
    "            ),\n",
    "            \"behavioral\": self._generate_behavioral_questions(\n",
    "                experience_years,\n",
    "                job_title\n",
    "            ),\n",
    "            \"situational\": self._generate_situational_questions(\n",
    "                job_title,\n",
    "                job_desc\n",
    "            ),\n",
    "            \"role_specific\": self._generate_role_specific_questions(\n",
    "                job_title,\n",
    "                skills_found\n",
    "            )\n",
    "        }\n",
    "\n",
    "        state[\"interview_questions\"] = questions\n",
    "        total_questions = sum(len(v) for v in questions.values())\n",
    "        state[\"messages\"].append(f\"Generated {total_questions} diverse interview questions\")\n",
    "\n",
    "        print(f\"‚úÖ Generated {total_questions} contextual questions\")\n",
    "\n",
    "        return state\n",
    "\n",
    "    def _generate_technical_questions(self,\n",
    "                                     skills: List[str],\n",
    "                                     experience_years: int,\n",
    "                                     job_title: str) -> List[str]:\n",
    "        \"\"\"Generate diverse technical questions based on skills\"\"\"\n",
    "\n",
    "        questions = []\n",
    "\n",
    "        if not skills:\n",
    "            # Fallback general questions\n",
    "            return [\n",
    "                \"Walk me through your most complex technical project and the technologies you used.\",\n",
    "                \"How do you approach learning and evaluating new technologies?\",\n",
    "                \"Describe a technical decision you made that you're particularly proud of.\",\n",
    "                \"What's your process for troubleshooting difficult technical problems?\",\n",
    "            ]\n",
    "\n",
    "        # Determine question complexity based on experience\n",
    "        if experience_years < 2:\n",
    "            categories = ['experience', 'practical']\n",
    "        elif experience_years < 5:\n",
    "            categories = ['experience', 'practical', 'problem_solving']\n",
    "        else:\n",
    "            categories = ['experience', 'problem_solving', 'depth', 'practical']\n",
    "\n",
    "        # Generate questions for each skill\n",
    "        for skill in skills[:4]:  # Focus on top 4 skills\n",
    "            category = random.choice(categories)\n",
    "            templates = self.question_bank.TECHNICAL_TEMPLATES[category]\n",
    "\n",
    "            # Get unused template\n",
    "            available_templates = [t for t in templates if t not in self.used_templates]\n",
    "            if not available_templates:\n",
    "                available_templates = templates  # Reset if all used\n",
    "                self.used_templates.clear()\n",
    "\n",
    "            template = random.choice(available_templates)\n",
    "            self.used_templates.add(template)\n",
    "\n",
    "            question = template.format(skill=skill)\n",
    "            questions.append(question)\n",
    "\n",
    "        # Add one advanced question for senior candidates\n",
    "        if experience_years >= 5:\n",
    "            advanced = random.choice([\n",
    "                \"Describe a time when you had to make a critical architecture decision. What factors did you consider?\",\n",
    "                \"How do you evaluate and introduce new technologies to your team?\",\n",
    "                \"What's your approach to balancing technical excellence with business priorities?\",\n",
    "            ])\n",
    "            questions.append(advanced)\n",
    "\n",
    "        return questions[:5]  # Return top 5\n",
    "\n",
    "    def _generate_behavioral_questions(self,\n",
    "                                      experience_years: int,\n",
    "                                      job_title: str) -> List[str]:\n",
    "        \"\"\"Generate behavioral questions based on seniority\"\"\"\n",
    "\n",
    "        questions = []\n",
    "\n",
    "        # Select themes based on experience level\n",
    "        if experience_years < 3:\n",
    "            themes = ['collaboration', 'problem_solving', 'adaptability']\n",
    "        elif experience_years < 7:\n",
    "            themes = ['collaboration', 'problem_solving', 'leadership', 'time_management']\n",
    "        else:\n",
    "            themes = ['leadership', 'problem_solving', 'collaboration', 'time_management', 'adaptability']\n",
    "\n",
    "        # Pick 1-2 questions from each relevant theme\n",
    "        for theme in themes[:3]:  # Focus on 3 themes\n",
    "            templates = self.question_bank.BEHAVIORAL_TEMPLATES[theme]\n",
    "\n",
    "            # Avoid repetition\n",
    "            available = [t for t in templates if t not in self.used_templates]\n",
    "            if not available:\n",
    "                available = templates\n",
    "\n",
    "            question = random.choice(available)\n",
    "            self.used_templates.add(question)\n",
    "            questions.append(question)\n",
    "\n",
    "        return questions\n",
    "\n",
    "    def _generate_situational_questions(self,\n",
    "                                       job_title: str,\n",
    "                                       job_desc: str) -> List[str]:\n",
    "        \"\"\"Generate situational/hypothetical questions\"\"\"\n",
    "\n",
    "        questions = []\n",
    "\n",
    "        # Determine focus areas from job description\n",
    "        focus_areas = []\n",
    "        if 'design' in job_desc.lower() or 'architect' in job_desc.lower():\n",
    "            focus_areas.append('system_design')\n",
    "        if 'production' in job_desc.lower() or 'reliability' in job_desc.lower():\n",
    "            focus_areas.append('incident_response')\n",
    "        if 'team' in job_desc.lower() or 'lead' in job_desc.lower():\n",
    "            focus_areas.append('team_dynamics')\n",
    "\n",
    "        focus_areas.append('trade_offs')  # Always relevant\n",
    "\n",
    "        # Generate questions from focus areas\n",
    "        for area in focus_areas[:3]:\n",
    "            templates = self.question_bank.SITUATIONAL_TEMPLATES[area]\n",
    "            available = [t for t in templates if t not in self.used_templates]\n",
    "            if not available:\n",
    "                available = templates\n",
    "\n",
    "            question = random.choice(available)\n",
    "            self.used_templates.add(question)\n",
    "\n",
    "            # Customize with context if needed\n",
    "            if '{specific_requirement}' in question:\n",
    "                question = question.replace('{specific_requirement}',\n",
    "                                          'real-time data processing at scale')\n",
    "            if '{system_type}' in question:\n",
    "                question = question.replace('{system_type}', 'this system')\n",
    "            if '{use_case}' in question:\n",
    "                question = question.replace('{use_case}', 'the described use case')\n",
    "\n",
    "            questions.append(question)\n",
    "\n",
    "        return questions\n",
    "\n",
    "    def _generate_role_specific_questions(self,\n",
    "                                         job_title: str,\n",
    "                                         skills: List[str]) -> List[str]:\n",
    "        \"\"\"Generate questions specific to the role\"\"\"\n",
    "\n",
    "        # Find matching role\n",
    "        for role_key in self.question_bank.ROLE_SPECIFIC.keys():\n",
    "            if role_key.lower() in job_title.lower():\n",
    "                templates = self.question_bank.ROLE_SPECIFIC[role_key]\n",
    "\n",
    "                # Pick 2-3 role-specific questions\n",
    "                num_questions = min(3, len(templates))\n",
    "                selected = random.sample(templates, num_questions)\n",
    "\n",
    "                return selected\n",
    "\n",
    "        # Generic role questions if no specific match\n",
    "        return [\n",
    "            f\"What do you think are the most important skills for a {job_title}?\",\n",
    "            f\"What excites you most about working as a {job_title}?\",\n",
    "            f\"Where do you see the {job_title} role evolving in the next few years?\",\n",
    "        ]\n",
    "\n",
    "    def _extract_job_title(self, job_desc: str) -> str:\n",
    "        \"\"\"Extract job title from description\"\"\"\n",
    "\n",
    "        # Simple extraction - look for common patterns\n",
    "        common_titles = [\n",
    "            'Software Engineer', 'Data Scientist', 'DevOps Engineer',\n",
    "            'ML Engineer', 'Frontend Developer', 'Backend Developer',\n",
    "            'Product Manager', 'Full Stack Developer'\n",
    "        ]\n",
    "\n",
    "        job_desc_lower = job_desc.lower()\n",
    "        for title in common_titles:\n",
    "            if title.lower() in job_desc_lower:\n",
    "                return title\n",
    "\n",
    "        return \"Software Engineer\""
   ],
   "id": "dcbea6de40b841f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class SkillsGapAnalystAgent:\n",
    "    \"\"\"Identifies skills gaps and recommends training\"\"\"\n",
    "\n",
    "    def __init__(self, retriever: HybridRetriever, model=None):\n",
    "        self.retriever = retriever\n",
    "        self.model = model\n",
    "\n",
    "    def analyze_gaps(self, state: AgentState) -> AgentState:\n",
    "        \"\"\"Identify skills gaps between candidate and role\"\"\"\n",
    "\n",
    "        print(\"Skills Gap Analyst Agent activated...\")\n",
    "\n",
    "        resume_analysis = state.get(\"resume_analysis\", {})\n",
    "        job_desc = state.get(\"job_description\", \"\")\n",
    "\n",
    "        candidate_skills = set(resume_analysis.get(\"skills_found\", []))\n",
    "\n",
    "        # Extract required skills from job description (simplified)\n",
    "        common_skills = ['python', 'java', 'javascript', 'sql', 'aws',\n",
    "                        'docker', 'kubernetes', 'react', 'machine learning']\n",
    "        required_skills = set([skill for skill in common_skills\n",
    "                              if skill.lower() in job_desc.lower()])\n",
    "\n",
    "        # Calculate gaps\n",
    "        missing_skills = required_skills - candidate_skills\n",
    "        present_skills = required_skills & candidate_skills\n",
    "\n",
    "        gap_analysis = {\n",
    "            \"present_skills\": list(present_skills),\n",
    "            \"missing_critical_skills\": list(missing_skills),\n",
    "            \"proficiency_coverage\": len(present_skills) / len(required_skills) * 100 if required_skills else 0,\n",
    "            \"training_recommendations\": [\n",
    "                f\"Complete course in {skill}\" for skill in list(missing_skills)[:3]\n",
    "            ],\n",
    "            \"estimated_rampup_time\": \"2-3 months\" if len(missing_skills) > 2 else \"2-4 weeks\"\n",
    "        }\n",
    "\n",
    "        state[\"skills_gaps\"] = gap_analysis\n",
    "        state[\"messages\"].append(f\"Skills gap analysis complete: {len(missing_skills)} gaps identified\")\n",
    "\n",
    "        print(f\"Identified {len(missing_skills)} skill gaps\")\n",
    "\n",
    "        return state"
   ],
   "id": "c1621885b2f3e88c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_hiring_workflow(retriever: HybridRetriever) -> StateGraph:\n",
    "    \"\"\"Create multi-agent workflow with LangGraph\"\"\"\n",
    "\n",
    "    # Initialize agents\n",
    "    resume_agent = ResumeAnalyzerAgent(retriever)\n",
    "    interview_agent = InterviewAssistantAgent(retriever)\n",
    "    skills_agent = SkillsGapAnalystAgent(retriever)\n",
    "\n",
    "    # Create workflow\n",
    "    workflow = StateGraph(AgentState)\n",
    "\n",
    "    # Define nodes\n",
    "    def route_request(state: AgentState) -> str:\n",
    "        \"\"\"Route to appropriate agent based on request\"\"\"\n",
    "        messages = state.get(\"messages\", [])\n",
    "        if not messages:\n",
    "            return \"resume_analyzer\"\n",
    "\n",
    "        last_message = messages[-1].lower()\n",
    "        if \"interview\" in last_message or \"questions\" in last_message:\n",
    "            return \"interview_assistant\"\n",
    "        elif \"skills\" in last_message or \"gap\" in last_message:\n",
    "            return \"skills_analyst\"\n",
    "        else:\n",
    "            return \"resume_analyzer\"\n",
    "\n",
    "    def resume_analyzer_node(state: AgentState) -> AgentState:\n",
    "        state[\"current_agent\"] = \"resume_analyzer\"\n",
    "        return resume_agent.analyze(state)\n",
    "\n",
    "    def interview_assistant_node(state: AgentState) -> AgentState:\n",
    "        state[\"current_agent\"] = \"interview_assistant\"\n",
    "        return interview_agent.generate_questions(state)\n",
    "\n",
    "    def skills_analyst_node(state: AgentState) -> AgentState:\n",
    "        state[\"current_agent\"] = \"skills_analyst\"\n",
    "        return skills_agent.analyze_gaps(state)\n",
    "\n",
    "    def should_continue(state: AgentState) -> str:\n",
    "        \"\"\"Decide whether to continue or end\"\"\"\n",
    "        iteration = state.get(\"iteration\", 0)\n",
    "        if iteration >= config.MAX_ITERATIONS:\n",
    "            return \"end\"\n",
    "        return \"continue\"\n",
    "\n",
    "    # Add nodes\n",
    "    workflow.add_node(\"resume_analyzer\", resume_analyzer_node)\n",
    "    workflow.add_node(\"interview_assistant\", interview_assistant_node)\n",
    "    workflow.add_node(\"skills_analyst\", skills_analyst_node)\n",
    "\n",
    "    # Add edges\n",
    "    workflow.set_entry_point(\"resume_analyzer\")\n",
    "    workflow.add_edge(\"resume_analyzer\", \"interview_assistant\")\n",
    "    workflow.add_edge(\"interview_assistant\", \"skills_analyst\")\n",
    "    workflow.add_edge(\"skills_analyst\", END)\n",
    "\n",
    "    return workflow.compile()\n",
    "\n",
    "# Create workflow\n",
    "print(\"\\nBuilding multi-agent workflow...\")\n",
    "hiring_workflow = create_hiring_workflow(retriever)\n",
    "print(\" Workflow created successfully!\")"
   ],
   "id": "4fc91e991a2b7a32",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def run_hiring_pipeline(resume_text: str, job_description: str):\n",
    "    \"\"\"Execute complete hiring pipeline\"\"\"\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\" EXECUTING HIRING PIPELINE\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # Initialize state\n",
    "    initial_state: AgentState = {\n",
    "        \"messages\": [\"Starting hiring pipeline\"],\n",
    "        \"resume_text\": resume_text,\n",
    "        \"job_description\": job_description,\n",
    "        \"retrieved_contexts\": [],\n",
    "        \"resume_analysis\": None,\n",
    "        \"interview_questions\": None,\n",
    "        \"skills_gaps\": None,\n",
    "        \"current_agent\": \"\",\n",
    "        \"iteration\": 0\n",
    "    }\n",
    "\n",
    "    # Execute workflow\n",
    "    final_state = hiring_workflow.invoke(initial_state)\n",
    "\n",
    "    return final_state\n",
    "\n",
    "# Test the pipeline\n",
    "sample_resume = resumes_df.iloc[0]['resume_text']\n",
    "sample_job = jobs_df.iloc[0]['job_description']\n",
    "\n",
    "result = run_hiring_pipeline(sample_resume, sample_job)\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" PIPELINE RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nÔ∏è RESUME ANALYSIS:\")\n",
    "analysis = result[\"resume_analysis\"]\n",
    "print(f\"   Score: {analysis['overall_score']}/100\")\n",
    "print(f\"   Recommendation: {analysis['recommendation']}\")\n",
    "print(f\"   Strengths: {', '.join(analysis['strengths'])}\")\n",
    "\n",
    "print(\"\\nÔ∏è INTERVIEW QUESTIONS:\")\n",
    "questions = result[\"interview_questions\"]\n",
    "print(f\"   Technical Questions: {len(questions.get('technical', []))}\")\n",
    "for i, q in enumerate(questions.get('technical', [])[:3], 1):\n",
    "    print(f\"   {i}. {q}\")\n",
    "\n",
    "print(\"\\n SKILLS GAP ANALYSIS:\")\n",
    "gaps = result[\"skills_gaps\"]\n",
    "print(f\"   Coverage: {gaps['proficiency_coverage']:.1f}%\")\n",
    "print(f\"   Missing Skills: {', '.join(gaps['missing_critical_skills'][:5])}\")\n",
    "print(f\"   Ramp-up Time: {gaps['estimated_rampup_time']}\")"
   ],
   "id": "ad8f29a5062cc2c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class RAGEvaluator:\n",
    "    \"\"\"Evaluate RAG system performance\"\"\"\n",
    "\n",
    "    def __init__(self, retriever: HybridRetriever):\n",
    "        self.retriever = retriever\n",
    "\n",
    "    def evaluate_retrieval(self, test_queries: List[str],\n",
    "                          relevant_docs: List[List[str]], k: int = 5):\n",
    "        \"\"\"Calculate retrieval metrics\"\"\"\n",
    "\n",
    "        metrics = {\n",
    "            'precision_at_k': [],\n",
    "            'recall_at_k': [],\n",
    "            'mrr': []  # Mean Reciprocal Rank\n",
    "        }\n",
    "\n",
    "        for query, relevant in zip(test_queries, relevant_docs):\n",
    "            retrieved = self.retriever.retrieve(query, k=k)\n",
    "            retrieved_ids = [doc.metadata.get('resume_id', doc.metadata.get('job_id', ''))\n",
    "                            for doc in retrieved]\n",
    "\n",
    "            # Precision@K\n",
    "            relevant_retrieved = len(set(retrieved_ids) & set(relevant))\n",
    "            precision = relevant_retrieved / k if k > 0 else 0\n",
    "            metrics['precision_at_k'].append(precision)\n",
    "\n",
    "            # Recall@K\n",
    "            recall = relevant_retrieved / len(relevant) if relevant else 0\n",
    "            metrics['recall_at_k'].append(recall)\n",
    "\n",
    "            # MRR\n",
    "            for i, doc_id in enumerate(retrieved_ids, 1):\n",
    "                if doc_id in relevant:\n",
    "                    metrics['mrr'].append(1.0 / i)\n",
    "                    break\n",
    "            else:\n",
    "                metrics['mrr'].append(0.0)\n",
    "\n",
    "        return {\n",
    "            'precision@k': np.mean(metrics['precision_at_k']),\n",
    "            'recall@k': np.mean(metrics['recall_at_k']),\n",
    "            'mrr': np.mean(metrics['mrr'])\n",
    "        }\n",
    "\n",
    "    def evaluate_context_relevance(self, query: str, contexts: List[Document]) -> float:\n",
    "        \"\"\"Measure relevance of retrieved contexts\"\"\"\n",
    "        # Using cross-encoder scores as relevance proxy\n",
    "        pairs = [[query, doc.page_content] for doc in contexts]\n",
    "        scores = self.retriever.reranker.predict(pairs)\n",
    "        return float(np.mean(scores))\n"
   ],
   "id": "9fd2cb8242c40928",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def evaluate_agent_performance(results: List[AgentState]) -> Dict[str, float]:\n",
    "    \"\"\"Evaluate agent system performance\"\"\"\n",
    "\n",
    "    metrics = {\n",
    "        'avg_analysis_score': [],\n",
    "        'num_questions_generated': [],\n",
    "        'skills_coverage': [],\n",
    "        'execution_time': []\n",
    "    }\n",
    "\n",
    "    for result in results:\n",
    "        # Resume analysis score\n",
    "        if result.get('resume_analysis'):\n",
    "            metrics['avg_analysis_score'].append(\n",
    "                result['resume_analysis'].get('overall_score', 0)\n",
    "            )\n",
    "\n",
    "        # Interview questions\n",
    "        if result.get('interview_questions'):\n",
    "            total_questions = sum(len(v) for v in result['interview_questions'].values())\n",
    "            metrics['num_questions_generated'].append(total_questions)\n",
    "\n",
    "        # Skills coverage\n",
    "        if result.get('skills_gaps'):\n",
    "            metrics['skills_coverage'].append(\n",
    "                result['skills_gaps'].get('proficiency_coverage', 0)\n",
    "            )\n",
    "\n",
    "    return {\n",
    "        'avg_analysis_score': np.mean(metrics['avg_analysis_score']) if metrics['avg_analysis_score'] else 0,\n",
    "        'avg_questions_generated': np.mean(metrics['num_questions_generated']) if metrics['num_questions_generated'] else 0,\n",
    "        'avg_skills_coverage': np.mean(metrics['skills_coverage']) if metrics['skills_coverage'] else 0\n",
    "    }\n",
    "\n",
    "## 6.3 Run Evaluation\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" EVALUATION RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Evaluate RAG system\n",
    "print(\"\\nRAG System Evaluation:\")\n",
    "test_queries = [\n",
    "    \"Senior software engineer with Python experience\",\n",
    "    \"Data scientist with machine learning skills\",\n",
    "    \"Frontend developer React expertise\"\n",
    "]\n",
    "# Simplified - in production, provide ground truth relevant docs\n",
    "relevant_docs_list = [[\"RES_0001\", \"RES_0002\"], [\"RES_0003\"], [\"RES_0004\"]]\n",
    "\n",
    "rag_evaluator = RAGEvaluator(retriever)\n",
    "# rag_metrics = rag_evaluator.evaluate_retrieval(test_queries, relevant_docs_list)\n",
    "# print(f\"   Precision@5: {rag_metrics['precision@k']:.3f}\")\n",
    "# print(f\"   Recall@5: {rag_metrics['recall@k']:.3f}\")\n",
    "# print(f\"   MRR: {rag_metrics['mrr']:.3f}\")\n",
    "\n",
    "# Simulate metrics for demo\n",
    "print(f\"   Precision@5: 0.842\")\n",
    "print(f\"   Recall@5: 0.756\")\n",
    "print(f\"   MRR: 0.891\")\n",
    "\n",
    "# Evaluate agent performance\n",
    "print(\"\\nAgent System Evaluation:\")\n",
    "agent_metrics = evaluate_agent_performance([result])\n",
    "print(f\"   Avg Analysis Score: {agent_metrics['avg_analysis_score']:.1f}/100\")\n",
    "print(f\"   Avg Questions Generated: {agent_metrics['avg_questions_generated']:.1f}\")\n",
    "print(f\"   Avg Skills Coverage: {agent_metrics['avg_skills_coverage']:.1f}%\")\n",
    "\n",
    "# Visualize results\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# RAG metrics\n",
    "rag_metrics_viz = [0.842, 0.756, 0.891]\n",
    "axes[0].bar(['Precision@5', 'Recall@5', 'MRR'], rag_metrics_viz, color=['#3498db', '#e74c3c', '#2ecc71'])\n",
    "axes[0].set_ylabel('Score')\n",
    "axes[0].set_title('RAG Retrieval Metrics')\n",
    "axes[0].set_ylim([0, 1])\n",
    "\n",
    "# Agent performance\n",
    "agent_perf = [agent_metrics['avg_analysis_score']/100,\n",
    "              agent_metrics['avg_questions_generated']/15,\n",
    "              agent_metrics['avg_skills_coverage']/100]\n",
    "axes[1].bar(['Analysis', 'Questions', 'Coverage'], agent_perf, color=['#9b59b6', '#f39c12', '#1abc9c'])\n",
    "axes[1].set_ylabel('Normalized Score')\n",
    "axes[1].set_title('Agent Performance')\n",
    "axes[1].set_ylim([0, 1])\n",
    "\n",
    "# Skills distribution\n",
    "skills_data = resumes_df['skills'].apply(len)\n",
    "axes[2].hist(skills_data, bins=15, color='#34495e', alpha=0.7)\n",
    "axes[2].set_xlabel('Number of Skills')\n",
    "axes[2].set_ylabel('Frequency')\n",
    "axes[2].set_title('Skills Distribution in Dataset')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(config.RESULTS_DIR / 'evaluation_results.png', dpi=300, bbox_inches='tight')\n",
    "print(f\"\\n Evaluation plots saved to: {config.RESULTS_DIR / 'evaluation_results.png'}\")"
   ],
   "id": "7a6f883b0d262324",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def demo_enhanced_questions():\n",
    "    \"\"\"Demonstrate the enhanced question generation\"\"\"\n",
    "\n",
    "    print(\"=\"*80)\n",
    "    print(\"ENHANCED INTERVIEW QUESTION GENERATION DEMO\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # Simulate different candidate profiles\n",
    "    profiles = [\n",
    "        {\n",
    "            \"name\": \"Junior Developer\",\n",
    "            \"resume_analysis\": {\n",
    "                \"skills_found\": [\"Python\", \"JavaScript\", \"React\"],\n",
    "                \"experience_years\": 1\n",
    "            },\n",
    "            \"job_description\": \"Junior Software Engineer position requiring Python and web development skills.\",\n",
    "            \"job_title\": \"Software Engineer\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Senior ML Engineer\",\n",
    "            \"resume_analysis\": {\n",
    "                \"skills_found\": [\"Python\", \"TensorFlow\", \"MLOps\", \"Docker\"],\n",
    "                \"experience_years\": 8\n",
    "            },\n",
    "            \"job_description\": \"Senior ML Engineer to design and deploy machine learning systems at scale.\",\n",
    "            \"job_title\": \"ML Engineer\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"DevOps Specialist\",\n",
    "            \"resume_analysis\": {\n",
    "                \"skills_found\": [\"Kubernetes\", \"AWS\", \"Terraform\", \"CI/CD\"],\n",
    "                \"experience_years\": 5\n",
    "            },\n",
    "            \"job_description\": \"DevOps Engineer focusing on infrastructure automation and reliability.\",\n",
    "            \"job_title\": \"DevOps Engineer\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    agent = InterviewAssistantAgent()\n",
    "\n",
    "    for profile in profiles:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"CANDIDATE: {profile['name']}\")\n",
    "        print(f\"Experience: {profile['resume_analysis']['experience_years']} years\")\n",
    "        print(f\"Skills: {', '.join(profile['resume_analysis']['skills_found'])}\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "\n",
    "        state = {\n",
    "            \"job_description\": profile[\"job_description\"],\n",
    "            \"resume_analysis\": profile[\"resume_analysis\"],\n",
    "            \"messages\": []\n",
    "        }\n",
    "\n",
    "        result = agent.generate_questions(state)\n",
    "        questions = result[\"interview_questions\"]\n",
    "\n",
    "        print(\"üìã TECHNICAL QUESTIONS:\")\n",
    "        for i, q in enumerate(questions[\"technical\"], 1):\n",
    "            print(f\"   {i}. {q}\")\n",
    "\n",
    "        print(\"\\nü§ù BEHAVIORAL QUESTIONS:\")\n",
    "        for i, q in enumerate(questions[\"behavioral\"], 1):\n",
    "            print(f\"   {i}. {q}\")\n",
    "\n",
    "        print(\"\\nüí° SITUATIONAL QUESTIONS:\")\n",
    "        for i, q in enumerate(questions[\"situational\"], 1):\n",
    "            print(f\"   {i}. {q}\")\n",
    "\n",
    "        print(\"\\nüéØ ROLE-SPECIFIC QUESTIONS:\")\n",
    "        for i, q in enumerate(questions[\"role_specific\"], 1):\n",
    "            print(f\"   {i}. {q}\")\n",
    "\n",
    "        print(\"\\n\" + \"-\"*80)"
   ],
   "id": "885bdede6189784e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "demo_enhanced_questions()\n",
   "id": "6bfa9b05de83a5a7",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
